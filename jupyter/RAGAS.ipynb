{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79b78b9-ca0a-4dd6-a283-fd11bc62e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d18a6a-c71f-4ff0-97b1-f20a1b549d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from src.text_gen.llm import load_llm_and_qa_tmpl\n",
    "from src.embedders.embedder import load_embedder\n",
    "from src.storing.storing import load_retriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a73312-c988-4e45-8b46-9f88faf1b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import EvaluationDataset\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "from ragas.integrations.llama_index import evaluate\n",
    "from ragas.metrics import (\n",
    "    AnswerRelevancy,\n",
    "    Faithfulness,\n",
    "    ContextPrecision,\n",
    "    ContextRecall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bc134f-cdf4-4527-8cd8-4387f53b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyp params\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    hyps = yaml.safe_load(f)\n",
    "\n",
    "logs_path: str = hyps['paths']['logs_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2c2155-afc0-4dfc-bdbe-ef0c6354b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "n = 10\n",
    "\n",
    "df = pd.read_json(f\"../{hyps['ragas']['ragas_dataset']}\").rename(columns={'question': 'user_input', 'answer': 'reference'})\n",
    "df = df.iloc[:n]\n",
    "\n",
    "ragas_dataset = EvaluationDataset.from_pandas(df[['user_input', 'reference']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc934e-5075-4624-9db4-81d6dace4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed\n",
    "query_embed_model_name: str = hyps['embed_model']['query_model_name']\n",
    "query_embed_kwargs: Optional[Dict] = hyps['embed_model']['query_kwargs']\n",
    "chunk_embed_model_name: str = hyps['embed_model']['chunk_model_name']\n",
    "chunk_embed_kwargs: Optional[Dict] = hyps['embed_model']['chunk_kwargs']\n",
    "\n",
    "query_embed_model = load_embedder(query_embed_model_name, logs_path=logs_path, model_kwargs=query_embed_kwargs)\n",
    "chunk_embed_model = load_embedder(chunk_embed_model_name, logs_path=logs_path, model_kwargs=chunk_embed_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56320d-8346-4d94-a2d7-6cdbc12d9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever\n",
    "vector_index_path: str = hyps['paths']['vector_index']\n",
    "k_vector_search: int = hyps['retriever']['k_vector_search']\n",
    "article_path: str = hyps['paths']['dataset_w_articles']\n",
    "bm25_index_path: str = hyps['paths']['text_index']\n",
    "k_text_search: int = hyps['retriever']['k_text_search']\n",
    "\n",
    "retriever = load_retriever(\n",
    "    vector_index_path,\n",
    "    chunk_embed_model,\n",
    "    logs_path,\n",
    "    k_vector_search,\n",
    "    article_path,\n",
    "    bm25_index_path,\n",
    "    k_text_search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071cf8c2-c5e6-47ab-9879-30ee3a8c9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-25 01:31:30 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 12-25 01:31:30 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='nvidia/Llama3-ChatQA-2-8B', speculative_config=None, tokenizer='nvidia/Llama3-ChatQA-2-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32000, download_dir='./hfcache', load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=nvidia/Llama3-ChatQA-2-8B, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 12-25 01:31:40 model_runner.py:1056] Starting to load model nvidia/Llama3-ChatQA-2-8B...\n",
      "INFO 12-25 01:31:40 weight_utils.py:243] Using model weights format ['*.bin']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e2673117b546d78e1e4c9a250edbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pt checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-25 01:31:55 model_runner.py:1067] Loading model weights took 14.9888 GB\n",
      "INFO 12-25 01:32:05 gpu_executor.py:122] # GPU blocks: 8296, # CPU blocks: 512\n",
      "INFO 12-25 01:32:05 gpu_executor.py:126] Maximum concurrency for 32000 tokens per request: 4.15x\n"
     ]
    }
   ],
   "source": [
    "# llm\n",
    "llm_model_name: str = hyps['llm_model']['model_name']\n",
    "max_new_tokens: int = hyps['llm_model']['max_new_tokens']\n",
    "cache_dir: str = hyps['paths']['cache_dir']\n",
    "logs_path: str = hyps['paths']['logs_db']\n",
    "\n",
    "llm, qa_prompt_tmpl = load_llm_and_qa_tmpl(\n",
    "    llm_model_name,\n",
    "    max_new_tokens,\n",
    "    cache_dir,\n",
    "    logs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57eb5b57-ba4e-4cae-ab4e-5ddc35643149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG query_engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,\n",
    "    embed_model=query_embed_model,\n",
    "    llm=llm,\n",
    "    text_qa_template=qa_prompt_tmpl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd32db-1a78-46c1-8e9f-3ec85579ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator llm\n",
    "generate_config = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 20,\n",
    "    \"top_p\": 0.8,\n",
    "    \"do_sample\": False,\n",
    "    \"num_beams\": 1,\n",
    "}\n",
    "\n",
    "eval_llm = HuggingFaceLLM(\n",
    "    model_name=hyps['ragas']['llm_evaluator'],\n",
    "    tokenizer_name=hyps['ragas']['llm_evaluator'],\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    generate_kwargs=generate_config,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"cuda:1\",\n",
    ")\n",
    "evaluator_llm = LlamaIndexLLMWrapper(eval_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46118ad3-b6b5-47a6-976f-ee6835e1d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "metrics = [\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    AnswerRelevancy(llm=evaluator_llm),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bd5a6-1f3c-414c-bc3d-2a8786c30e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "result = evaluate(\n",
    "    query_engine=query_engine,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=query_embed_model,\n",
    "    dataset=ragas_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370c8835-b6d0-4d21-bb79-2dcd14d13c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель генерации: nvidia/Llama3-ChatQA-2-8B\n",
      "Кол-во чанков из векторного поиска: 3\n",
      "Кол-во чанков из текстового поиска: 3\n",
      "Модель оценщик: google/gemma-2-9b-it\n",
      "Метрики: {'faithfulness': 0.7778, 'answer_relevancy': 0.5426}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "Модель генерации: {llm_model_name}\n",
    "Кол-во чанков из векторного поиска: {k_vector_search}\n",
    "Кол-во чанков из текстового поиска: {k_text_search}\n",
    "Модель оценщик: {hyps['ragas']['llm_evaluator']}\n",
    "Метрики: {result}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fba7e-b8af-4fdb-8791-82d4591be56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
