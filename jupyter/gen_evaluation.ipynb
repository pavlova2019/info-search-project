{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ba95be-cf79-41fd-acec-4a9cd1ca7823",
   "metadata": {},
   "source": [
    "### libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cfdf99-b632-4606-a03e-a98230ecc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '../hfcache'\n",
    "os.environ['HF_HOME'] = '../hfcache'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc03f7b-fa19-4ec4-9974-f8a1c7a440a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c74e9d1-be31-4937-9485-de2396a1188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, gc, pprint\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde03438-313e-4cb7-b345-f5ab60552d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cache_dir = '../hfcache'\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd25d32-12a5-4b45-8057-73a9fbb039ae",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1559332-559f-4de5-b165-170e1503c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"nvidia/Llama3-ChatQA-1.5-8B\": \"nvidia_llama3_8b\",  # context 8k\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\": \"qwen2.5_7b\",  # context 32k\n",
    "    \"microsoft/Phi-3.5-mini-instruct\": \"phi3.5_mini\",  # context 128k\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\": \"mistral_nemo_12b\"  # context 128k\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672ee096-ece1-4cd5-8847-fd2ccff96370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f01acfb8c5f41788221c17b91f3d7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/780 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2bcce42fe94ce08dfba8408d71a662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69a5969dcd24f7d96904ab46cc471a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/322 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9650b26c3b422788a020f2ff5cac3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e033feccc94c0e866d9c24b5b18e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b6e0b5561d4961afa848bde596ce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bleurt\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Elron/bleurt-large-512\", cache_dir=cache_dir, device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Elron/bleurt-large-512\", cache_dir=cache_dir, device_map=device)\n",
    "model.eval()\n",
    "\n",
    "bertscore = load(\"bertscore\", module_type=\"metric\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298d815c-ccf3-45ed-ac5e-aec1168cdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_score = {}\n",
    "for model_name, title in model_names.items():\n",
    "    path = os.path.join(data_dir, f\"{title}_gen.csv\")\n",
    "    data = pd.read_csv(path, )\n",
    "    \n",
    "    bertscore_results = bertscore.compute(predictions=data[\"Gen\"].tolist(), references=data[\"True\"].tolist(), lang=\"en\", )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(data[\"True\"].tolist(), data[\"Gen\"].tolist(),\n",
    "                           return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        scores = model(**inputs)[0].squeeze()\n",
    "    \n",
    "    results_score[title] = {\n",
    "        'precision': np.mean(bertscore_results['precision']).item(),\n",
    "        'recall': np.mean(bertscore_results['recall']).item(),\n",
    "        'f1': np.mean(bertscore_results['f1']).item(),\n",
    "        'bleurt': scores.mean().item()\n",
    "    }\n",
    "\n",
    "    del inputs, scores\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45509804-17a2-463c-91be-873937d1dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistral_nemo_12b': {'bleurt': -0.08434377610683441,\n",
      "                      'f1': 0.8664473816752434,\n",
      "                      'precision': 0.8384463673830033,\n",
      "                      'recall': 0.8969514963030815},\n",
      " 'nvidia_llama3_8b': {'bleurt': -0.18476881086826324,\n",
      "                      'f1': 0.9070042352378368,\n",
      "                      'precision': 0.9294992500543594,\n",
      "                      'recall': 0.8864519880712032},\n",
      " 'phi3.5_mini': {'bleurt': 0.00402071001008153,\n",
      "                 'f1': 0.8730380964279175,\n",
      "                 'precision': 0.8471604603528976,\n",
      "                 'recall': 0.9009352257847786},\n",
      " 'qwen2.5_7b': {'bleurt': -0.058741774410009384,\n",
      "                'f1': 0.8638190342485905,\n",
      "                'precision': 0.8339289693534374,\n",
      "                'recall': 0.8964014400541782}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(results_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88860648-5cd6-451a-b319-7bc44a48d966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
